{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cda9f5-0344-4b39-9c98-0d22eb744676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f40f5e-9e3e-47d1-8873-d35eb5f16464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to Implemement ADAMW as my optimizer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4212fde-ae2c-4759-81a1-7c2e451cc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chopped and changed class\n",
    "class FFN_change:\n",
    "    def __init__(self, input_data, output_data, hidden_layers, activation_functions, epochs, learning_rate, batch_size):\n",
    "        self.input_data = input_data  # Make sure this is a numpy array\n",
    "        self.output_data = output_data\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation_functions = activation_functions\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.weights_dictionary = {}\n",
    "        self.activations_dictionary = {}\n",
    "        self.initialize()\n",
    "##### an improvement could be if you have a method that allows you to input new data to further train your data\n",
    "    def initialize(self):\n",
    "        last_layer = self.input_data.shape[0]\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            self.weights_dictionary[f'w{i}'] = 0.1 * np.random.randn(self.hidden_layers[i], last_layer)\n",
    "            self.weights_dictionary[f'b{i}'] = np.zeros((self.hidden_layers[i], 1))\n",
    "            last_layer = self.hidden_layers[i]\n",
    "        self.weights_dictionary['last_weight'] = 0.1 * np.random.randn(self.output_data.shape[0], last_layer)\n",
    "        self.weights_dictionary['last_bias'] = np.zeros((self.output_data.shape[0], 1))\n",
    "        \n",
    "    def forward(self, input_batch): \n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            z = np.dot(self.weights_dictionary[f'w{i}'], input_batch) + self.weights_dictionary[f'b{i}']\n",
    "            a = self.activation(z, self.activation_functions[i])\n",
    "            self.activations_dictionary[f'z{i + 1}'] = z\n",
    "            self.activations_dictionary[f'a{i + 1}'] = a\n",
    "            input_batch = a  \n",
    "        a = np.dot(self.weights_dictionary['last_weight'], input_batch) + self.weights_dictionary[\"last_bias\"]\n",
    "        self.activations_dictionary['activation_output'] = a\n",
    "\n",
    "    def activation(self, a, activation_function):\n",
    "        if activation_function[0] == \"relu\":\n",
    "            return np.maximum(0, a)\n",
    "        elif activation_function[0] == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-a))\n",
    "        elif activation_function[0] == \"tanh\":\n",
    "            return np.tanh(a)\n",
    "        elif activation_function[0] == \"lrelu\":\n",
    "            return np.maximum(activation_function[1] * a, a) \n",
    "        else:\n",
    "            raise Exception(\"Invalid activation function\")\n",
    "\n",
    "    def activation_derivative(self, a, activation_function):\n",
    "        if activation_function[0] == 'relu':\n",
    "            return np.where(a > 0, 1, 0)\n",
    "        elif activation_function[0] == 'sigmoid':\n",
    "            sig = self.activation(a, ('sigmoid', 0))\n",
    "            return sig * (1 - sig)\n",
    "        elif activation_function[0] == 'tanh':\n",
    "            return 1 - np.tanh(a) ** 2\n",
    "        elif activation_function[0] == 'lrelu':\n",
    "            dx = np.ones_like(a)\n",
    "            dx[a <= 0] = activation_function[1]\n",
    "            return dx\n",
    "        else:\n",
    "            raise Exception(\"Invalid activation function derivative\")\n",
    "\n",
    "    def backward(self, dvalues, input_batch):\n",
    "        i = len(self.hidden_layers)\n",
    "        self.weights_dictionary[\"dweights last_weight\"] = np.dot(dvalues, self.activations_dictionary[f'a{i}'].T)\n",
    "        self.weights_dictionary[\"dbiases last_bias\"] = np.sum(dvalues, axis=1, keepdims=True)\n",
    "        dinputs = np.dot(self.weights_dictionary[\"last_weight\"].T, dvalues)\n",
    "        \n",
    "        for i in range(len(self.hidden_layers) - 1, -1, -1):\n",
    "            dinputs *= self.activation_derivative(self.activations_dictionary[f'z{i + 1}'], self.activation_functions[i])\n",
    "            self.weights_dictionary[f'dweights{i}'] = np.dot(dinputs, self.activations_dictionary[f'a{i}'].T if i > 0 else input_batch.T)\n",
    "            self.weights_dictionary[f'dbiases{i}'] = np.sum(dinputs, axis=1, keepdims=True)\n",
    "            if i > 0:\n",
    "                dinputs = np.dot(self.weights_dictionary[f'w{i}'].T, dinputs)\n",
    "\n",
    "    def compute_loss(self, predictions, targets):\n",
    "        return np.mean((predictions - targets) ** 2) \n",
    "\n",
    "    def loss_backwards(self, predictions, targets):\n",
    "        return 2 * (predictions - targets) / targets.shape[1] \n",
    "\n",
    "    def train(self):\n",
    "        epoch_data = []\n",
    "        loss_history = []\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for start in range(0, self.input_data.shape[1], self.batch_size):\n",
    "                end = min(start + self.batch_size, self.input_data.shape[1])\n",
    "                input_batch = self.input_data[:, start:end]\n",
    "                output_batch = self.output_data[:, start:end]\n",
    "                \n",
    "                self.forward(input_batch)\n",
    "                loss = self.compute_loss(self.activations_dictionary[\"activation_output\"], output_batch)\n",
    "                dvalues = self.loss_backwards(self.activations_dictionary[\"activation_output\"], output_batch)\n",
    "                self.backward(dvalues, input_batch)\n",
    "                self.update()\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                batch_count += 1\n",
    "            \n",
    "            epoch_loss /= batch_count\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {epoch_loss}\")\n",
    "                epoch_data.append(epoch)\n",
    "                loss_history.append(epoch_loss)\n",
    "\n",
    "        plt.plot(epoch_data, loss_history)\n",
    "        plt.xlabel(\"Epoch Number\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Epoch Number vs Loss\")\n",
    "        plt.show()\n",
    "        \n",
    "    def update(self):\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            self.weights_dictionary[f'w{i}'] -= self.learning_rate * self.weights_dictionary[f'dweights{i}']\n",
    "            self.weights_dictionary[f'b{i}'] -= self.learning_rate * self.weights_dictionary[f'dbiases{i}']\n",
    "        self.weights_dictionary[\"last_weight\"] -= self.learning_rate * self.weights_dictionary[\"dweights last_weight\"]\n",
    "        self.weights_dictionary[\"last_bias\"] -= self.learning_rate * self.weights_dictionary[\"dbiases last_bias\"]\n",
    "\n",
    "\n",
    "    def predict(self, input_data, output_data):\n",
    "        self.forward(input_data)\n",
    "        loss = self.compute_loss(self.activations_dictionary[\"activation_output\"], output_data)\n",
    "        return loss, self.activations_dictionary[\"activation_output\"]\n",
    "\n",
    "    def forecast(self, input):\n",
    "        self.forward(input)\n",
    "        return self.activations_dictionary[\"activation_output\"]\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
